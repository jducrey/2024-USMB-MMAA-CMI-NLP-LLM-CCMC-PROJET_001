# PROJET_001
Projet en Traitement du Langage Naturel (NLP)
Exploration des concepts et des m√©canismes, √† la base du fonctionnement des Grands Mod√®les de Langage (LLM) et des Cha√Ænes de Markov Conditionn√©e au Contexte (CCMC),
au travers de recherches personnelles et de la lecture d'un article, traitant de ce sujet.

Parmi les notions abord√©es, on compte notamment: 
- Tokenizer (SpaCy, BPE, Wordpiece)
- Word Embedding (TF-IDF, Word2Vec)
- Self-Attention
- Transformer Architecture
- Context-Conditionned Markov Chain (Transition Matrix, Prompt Mask)

### Bijection between LLM and CCMC, on their probabilities distributions.
### Prediction based on the structure of a vector space derived from word embeddings.

#### Article √©tudi√©:
From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers.
M. Emrullah Ildiz, Yixiao Huang, Yingcong Li, Ankit Singh Rawat, Samet Oymak.  
Lien de l'article utilis√© pour l'√©tude: https://arxiv.org/abs/2402.13512

üéì Projet r√©alis√© dans le cadre du Master MMAA ‚Äì Universit√© Savoie Mont Blanc
