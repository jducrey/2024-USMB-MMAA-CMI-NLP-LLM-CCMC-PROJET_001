# 2024-USMB-MMAA-CMI-NLP - LLM & CCMC : Une Exploration Contextuelle

Projet universitaire en **Traitement Automatique du Langage Naturel (NLP)**, combinant recherche autodidacte et analyse d’un article de recherche de pointe.  

L'objectif : Comprendre et illustrer les concepts et les mécanismes internes, à la base du fonctionnement des **Grands Modèles de Langage (LLM)** et des **Chaînes de Markov Conditionnées au Contexte (CCMC)**.

---

## 🎯 Objectifs

- Explorer les concepts fondamentaux des LLM, à travers une approche théorique et appliquée.
- Mettre en lumière les **liens entre les architectures Transformers et les chaînes de Markov contextuelles**.
- Analyser comment la structure vectorielle des représentations lexicales influence la prédiction.

---

## 🧩 Notions abordées

- **Tokenization** : SpaCy, Byte Pair Encoding (BPE), WordPiece
- **Word Embeddings** : TF-IDF, Word2Vec
- **Self-Attention** & **Architecture Transformer**
- **Chaîne de Markov Conditionnées au Contexte ou Context-Conditionned Markov Chain (CCMC)**
  - Matrice de transition
  - Masque de Prompt (Prompt Mask)
- **Distribution de probabilité dans les LLM vs CCMC**

---

## 🔬 Analyse théorique

### 🔄 Bijection entre LLM et CCMC
> Étude des correspondances entre les distributions de probabilité générées par un LLM et celles issues d’une chaîne de Markov contextuelle.

### 🧭 Prédiction dans l’espace vectoriel
> Analyse de la dynamique de prédiction dans un espace dérivé de l’embedding des mots.

---

## 📚 Article de référence
**"From Self-Attention to Markov Models: Unveiling the Dynamics of Generative Transformers"**.
_M. Emrullah Ildiz, Yixiao Huang, Yingcong Li, Ankit Singh Rawat, Samet Oymak_  
🔗 [Lire l’article sur arXiv](https://arxiv.org/abs/2402.13512)

---

## 🎓 Contexte académique

Projet réalisé dans le cadre du **Master MMAA – Université Savoie Mont Blanc**  
Approche mêlant rigueur mathématique et curiosité personnelle sur les enjeux modernes de l’IA.

---

## 💬 Suggestions, remarques, questions ?
N'hésitez pas à ouvrir une *issue* ou me contacter directement via GitHub !
